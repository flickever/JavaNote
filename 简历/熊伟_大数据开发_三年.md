# 熊伟\_大数据开发_三年

## 个人信息

- 姓   名：熊伟                            	  						    年龄：26
- 工作经验：3.5年                                                   学历：本科
- 目前状况：在职                                                    岗位：IT开发工程师
- 电话：18339955330                                              邮箱：xiongv.ever@outlook.com

## 专业技能

- 掌握Java和Scala编程，熟悉使用Python开发；
- 掌握Hadoop架构，熟悉HDFS的基本操作与原理，熟悉Yarn的任务分配调度流程；
- 掌握HiveSQL的编写，及数据分层、建模、优化等；
- 掌握数据仓库模型建设；
- 熟悉Flink工作流程以及了解运行原理；能够使用 Flink 进行流式计算；
- 熟悉JVM内存区域划分及垃圾回收过程。
- 熟悉Kafka相关原理，使用Kafka构建实时数据流管道，与Flink实时数据流整合；
- 熟悉Hbase的存储机制以及优化；
- 掌握使用DataX对数据和数据库之间进行出导入导出；
- 了解 Zookeeper、Flume、Sqoop、Hive 等大数据组件的使用；
- 了解Flink的水位线和背压机制，使用过Flink CEP进行代码开发；
- 了解使用Flink SQL；
- 了解Druid，Kylin等OLAP分析引擎；

## 工作经历

**在职时间**                   **所属行业**         **公司名称**                                                       **担任职位**

2017.06--2018.04       电子商务	    郑州万国优品保税进出口有限公司             数据开发工程师

2018.07--2020.02       智能硬件        宁波舜宇光学科技有限公司                         数据开发工程师

2020.05--至今            手机通讯        华勤技术股份有限公司                                 数据平台开发

## 项目经历

**2020.5-至今**                                                              **项目名称：华勤质量云中枢离线项目**

**项目描述：**

​		为对公司生产、售后过程中产品质量问题进行监控、可视化展示供管理层决策并对制造部门考核而发起。从业务系统中抽取生产、检验、售后信息上云，以ERP主数据作为维度信息实现分析，分析结果传入关系型数据库供帆软调用；

​		主要负责公司质量域的开发工作，由于质量部门没有自己的业务系统，所以需要与业务沟通数据来源，并进行数据抽取、探查等工作。完成模型ODS到ADS数据开发，其中字段翻译需要遵守公司词素库，模型在开发并评审完成后需要上传公司DDM模型库中，并更新指标字典。

​		同时担任公司大数据平台运维工作，针对慢SQL任务会进行专项优化调整，同时对开发同事的一些SQL报错（非语法报错）找出解决办法。

​		维护部分公共域主数据表，并对业务系统提供数据接口服务。

**软件架构：DataWorks + E-MapReduce + OSS + Ranger + ADB PostgreSQL + Serverless +  FineReport** 

**责任描述：**

​	**模型开发：**根据业务方需求，抽取业务系统数据上云，确定业务逻辑，实现从ODS、CDM到ADS以及ADB PG一整套模型开发；

​	**数据分析**：创建生产、检验、售后信息事实表，根据提供指标进行相关分析，满足业务需求；

​	**平台运维**：负责阿里云平台的运维保障，配置调整，成功解决过一次集群内存泄漏问题，并给出预警办法；

​	**任务调优：**对项目重点任务调优，帮助解决部分Hive任务频繁OOM、以及运行时间过长问题；

​	**平台开发：**阿里云平台二次开发，对Hive任务产生的Yarn任务进行分析，如分析任务时长、或执行频率等；

​	**承担临时任务：**根据要求开发Python脚本



**2019.5-2020.2**                                                       **项目名称：舜宇工业大数据项目[实时]**

**项目描述：**

​		舜宇工业大数据项目是舜宇光电为提升产品良率，采集工业生产各个环节实时信息，实时分析处理后发送反馈信息，通过收集原料、机台、操作日志信息等，分析处理后及时得到实时生产信息，帮助生产部门领导及现场技术人员得到各环节良率信息，便于在良率降低时及时响应，快速定位问题，降低企业生产成本； 

**软件架构：Mysql + Flink + Kafka + Canal + Redis + Hbase + Phoenix + Driuid + Flume**

**责任描述：**

​	**数据同步**：对接公司MES系统，产品状态信息存储于MySQL，一旦发生改变，Cancal获取bin-log更改信息下沉到Kafka的ods层；存于MySQL中的维度信息如果发生更改，由Canal 发送到Flink程序，Flink程序处理后同步修改Redis中的维度数据；

​	**数据处理**：主要利用Flink程序消费Kafka中ods层字段，对数据进行过滤拉宽，关联Redis中存好的维度信息（产品、工位、人员、客户等维度），处理完成的数据向Kafka的dw层和HBase各发送一份；

​	**数据分析**：Druid预处理Kafka中dw层数据，保存计算后数据；

​	                 	Phoenix查询Hbase数据，构建Hbase二级索引，提升查询效率；



**2018.7-2019.4**                                                    **项目名称：舜宇工业大数据项目[离线]**

**项目描述：**

为分析深入分析良率影响因素，搭建离线数仓分析数据，离线分析有助于部门领导及现场技术人员通过查看某一周期的生产数据，以直观的统计数据查找到对于生产影响较大的信息，如机台Mac、供应商来料、不良集中工序等；

**软件架构：MySQL+Hadoop+Hive+SparkSQL +Kylin+HBase+DataX**

**责任描述：**

​	**数据采集：**    使用DataX同步MySQL数据到Hive的ods层，供后续数据处理； Flume获取生产日志信息，同步到HDFS，再使用SparkSQL将HDFS数据同步到hive的ods层；

​	**数据处理：**    使用SparkSQL进行数据ETL操作； Spark范围分区解决数据倾斜问题；

​	**数据分析：**    Kylin预计算作为数据仓库的ads层；



## **自我评价**

1. 有较强的适应能力和接触新事物的能力，学习能力较强；
2. 能很快适应新的工作环境，融入团队中去，善于学习新的知识，有一定的自学能力；
3. 乐于与用户以及同事和领导沟通，以便快速解决项目遇到的问题；
4. 喜欢互联网行业，对新技术有较强的学习能力；

