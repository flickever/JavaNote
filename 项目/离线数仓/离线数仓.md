# 离线数仓

## 项目描述

**数据来源**

- 业务系统数据库数据
- 前端埋点日志
- 爬虫数据

**使用工具**

Flume：可分布式日志收集系统，框架比较清晰，比如source，channel，sink的概念。而且是用java开发的，二次开发也很方便。大公司都在用，表现稳定，方便实时监控传输数据

Sqoop：基于MR程序，且只有Map任务



## 项目需求

1. 用户行为数据采集
2. 业务数据采集
3. 数据仓库维度建模
4. 分析指标（设备、会员、商品、地区、活动等电商主题）100多个
5. 即席查询支持临时任务
6. 集群性能监控
7. 元数据管理
8. 数据质量监控
9. 权限管理



## 技术选型

- 数据采集：`Flume`、`Kafka`、`Sqoop`、`Logstash`、`DataX`
- 数据存储：`MySQL`、`HDFS`、`HBase`、`Redis`、`MongoDB`
- 数据计算：`Hive`、`Tez`、`Spark`、`Flink`、`Storm`
- 数据查询：`Presto`、`Kylin`、`Impala`、`Druid`、`ClickHouse`、`Doris`
- 数据可视化：`Echarts`、`Superset`、`QuickBI`、`DataV`
- 任务调度：`Azkaban`、`Ooize`、`DolpinSceduler`、`AirFlow`
- 集群监控：`Zabbix`、`Prometheus`
- 元数据管理：`Atlas`
- 权限管理：`Ranger`、`Sentry`



**选型**

ELK应用于数据量不是巨大的场合，DataX和Sqoop目前市场占有率五五开

MySQL用于数据量小的场合，一般存结果数据（ADS）

HBase一般存Kylin预计算数据，Rdis可用于实时计算中

Tez数据完全放在内存，Spark数据部分在内存，部分在磁盘

在离线中这次使用Zabbix，在实时中使用Prometheus

元数据管理Atlas解决问题：查看任务影响范围（指标输出）

Ranger控制哪些用户可以看哪些表，Sentry已经被Apache除名了



**系统流程**

![img](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93/01_%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86wps44A3.tmp.png)



**框架版本**

采用Apache版本，因为CDH版本开始收费，不收费版本太过老旧

![image-20220212221844272](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93/01_%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E9%87%87%E9%9B%86image-20220212221844272.png)



## 采集内容

**页面信息**

页面id：本页面id

上页id：从哪个页面过来的

页面对象类型：商品

页面对象id：商品id

页面来源类型：搜索、跳转....

停留时间：30000秒

跳入时间：时间戳类型



**事件信息**

添加收藏、取消收藏、添加购物车.......



**曝光信息**

曝光类型：商品推广、算法推荐商品、查询结果商品、促销活动

曝光对象类型：商品skuId、活动id

曝光对象id

曝光顺序



**启动信息**

启动入口：图标、通知、安装后启动

启动加载时间

开屏广告id

广告播放时间

用户跳过广告时间

启动时间



**错误信息**

错误码、错误信息



## 集群配置

**压缩类型优缺点**

目前在Hadoop中用得比较多的有lzo，gzip，snappy，bzip2这4种压缩格式，实践中应根据实际情况选择不同的压缩格式。

1、gzip压缩

优点：压缩率比较高，而且压缩/解压速度也比较快；hadoop本身支持，在应用中处理gzip格式的文件就和直接处理文本一样；有hadoop native库；大部分linux系统都自带gzip命令，使用方便。

缺点：不支持split。

应用场景：当每个文件压缩之后在130M以内的（1个块大小内），都可以考虑用gzip压缩格式。譬如说一天或者一个小时的日志压缩成一个gzip文件，运行mapreduce程序的时候通过多个gzip文件达到并发。hive程序，streaming程序，和java写的mapreduce程序完全和文本处理一样，压缩之后原来的程序不需要做任何修改。

2、lzo压缩

优点：压缩/解压速度也比较快，合理的压缩率；支持split，是hadoop中最流行的压缩格式；支持hadoop native库；可以在linux系统下安装lzop命令，使用方便。

缺点：压缩率比gzip要低一些；hadoop本身不支持，需要安装；在应用中对lzo格式的文件需要做一些特殊处理（为了支持split需要建索引，还需要指定inputformat为lzo格式）。

应用场景：一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，lzo优点越越明显。

3、snappy压缩

优点：高速压缩速度和合理的压缩率；支持hadoop native库。

缺点：不支持split；压缩率比gzip要低；hadoop本身不支持，需要安装；linux系统下没有对应的命令。

应用场景：当mapreduce作业的map输出的数据比较大的时候，作为map到reduce的中间数据的压缩格式；或者作为一个mapreduce作业的输出和另外一个mapreduce作业的输入。

4、bzip2压缩

优点：支持split；具有很高的压缩率，比gzip压缩率都高；hadoop本身支持，但不支持native；在linux系统下自带bzip2命令，使用方便。

缺点：压缩/解压速度慢；不支持native。

应用场景：适合对速度要求不高，但需要较高的压缩率的时候，可以作为mapreduce作业的输出格式；或者输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；或者对单个很大的文本文件想压缩减少存储空间，同时又需要支持split，而且兼容之前的应用程序（即应用程序不需要修改）的情况。





Orc文件描述：[Hive数仓建表该选用ORC还是Parquet，压缩选LZO还是Snappy？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/257917645)

**lzo压缩**

LZO相比较压缩，更追求速度，如果想让数据可以切分，需要创建LZO索引

不创建索引的后果是，不管文件有多大，都会只有一个Map读取