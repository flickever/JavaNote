# 01_数据采集层

## 1. 数仓分层介绍

**为什么要分层**

为了当出现多个需求时候，多需求可以同复用一张表，而不是从头到尾再抽取一遍，从而实现数据的**复用性**，另外还有解耦、拓展性高等好处

![page2_image3](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82page2_image3.jpg)

而**普通的实时计算**优先考虑时效性，所以从数据源采集经过实时计算直接得到结果。如此做时效性更好，但是弊端是由于计算过程中的中间结果没有沉淀下来，所以当面对大量实时需求的时候，计算的复用性较差，开发成本随着需求增加直线上升。

![page1_image2](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82page1_image2.jpg)



**分层介绍**

ODS：原始数据，日志和业务数据

DWD：根据数据对象为单位进行分流（例如侧输出流），比如订单、页面访问等等

DIM：维度数据（放HBase，因为实时流中Join相当于查询，且维度数据需要永久保存）

DWM：对于部分数据对象进行进一步加工，比如独立访问、跳出行为，也可以和维度进行关联，形成宽表，依旧是明细数据。

DWS：根据某个主题将多个事实数据轻度聚合，形成主题宽表。（存到Clickhouse）

ADS：把ClickHouse中的数据根据可视化需进行筛选聚合（不落盘）





## 2.  实时需求概览

**离线计算与实时计算的比较**

**离线计算**：就是在计算开始前已知所有输入数据，输入数据不会产生变化，一般计算量级较大，计算时间也较长。例如今天早上一点，把昨天累积的日志，计算出所需结果。最经典的就是 Hadoop 的 MapReduce 方式；

一般是根据前一日的数据生成报表，虽然统计指标、报表繁多，但是对时效性不敏感。从技术操作的角度，这部分属于批处理的操作。即根据确定范围的数据一次性计算。

**实时计算**：输入数据是可以以序列化的方式一个个输入并进行处理的，也就是说在开始的时候并不需要知道所有的输入数据。与离线计算相比，运行时间短，计算量级相对较小。强调计算过程的时间要短，即所查当下给出结果。

主要侧重于对当日数据的实时监控，通常业务逻辑相对离线需求简单一下，统计指标也少一些，但是更注重数据的时效性，以及用户的交互性。从技术操作的角度，这部分属于流处理的操作。根据数据源源不断地到达进行实时的运算。

**即席查询**：需求临时性（Presto、Kylin）



**实时需求种类**

- **日常统计报表或分析图中需要包含当日部分**
- **实时数据大屏监控**
- **数据预警或提示**
- **实时推荐系统**



## 3. 架构分析

**离线**

![image-20220201143631865](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82image-20220201143631865.png)

**实时**

![image-20220201143711363](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82image-20220201143711363.png)



**Sqoop**：

- 全量：where 1=1
- 增量：创建时间  = 当天
- 增量及变化：创建时间  = 当天  or  操作时间  = 当天
- 特殊：只导入一次



### 3.1 FlumeSource

**FlumeTailSource**：

- 优点：断点续传，多目录多文件实时监控
- 缺点：文件更名后，会重新读取造成数据重复
- 原因：flume监控文件的inode、filename、偏移量，inode和filename一旦改变就认为是一个新文件
- 解决办法：
  - 使用不更名日志框架（logback），但上游可能不愿意改
  - 自己改flume源码，让TailSource只监控inode
- 可不可以把监控文件名写死呢
  - 不可以，当若上游使用log4j，零点时日志文件更名并生成新的同名文件，inode值会变，偏移量会变
  - 如果flume在11点半挂了，0点启动，由于文件更名，导致中间30分钟数据监控不到



### 3.2 KafkaChannel

**KafkaChannel**：

- 优点：数据写入Kafka省去一层sink



Kafak的一些面试点：

**Producer**

- ACK（0，1，-1）
- 拦截器、序列化、分区器
- 发送流程、sender、main
- 幂等性、事务
- 分区规则
  - 有指定分区规则就发往指定分区（优先级最高）
  - 没有指定分区就根据Key来Hash
  - 没有指定分区也没有指定Key，轮询（粘性）



**Broker**

- Topic
  - 副本：高可靠，ISR（LEO、HW）
  - 分区：高并发，负载均衡，防止热点



**Consumer**

- 分区分配规则
- offset保存问题
  - 默认__consumer_offsets  Topic
  - 手动维护（MySQL），保存offset&保存数据写到一个事务，实现精准一次消费



优化、监控、配置、数据量、峰值速度



### 3.3 架构对比

**离线架构**

- 优点：耦合性低，稳定性高
- 缺点：时效性差
- 说明：
  - 追求系统稳定性
  - 耦合性低，稳定性高
  - 考虑未来发展，数据量一定很高



**实时架构**

- 优点：时效性好
- 缺点：耦合性高，稳定性低
- 说明：
  - Flink时效性好
  - Kafka集群高可用，挂两台没关系
  - 数据量小，在同机房传输没问题
  - 架构师定的



## 4. 日志采集

![page7_image2](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82page7_image2.jpg)

由于条件限制，只能直接对Spring boot做请求发送假数据，不再经过Nginx

