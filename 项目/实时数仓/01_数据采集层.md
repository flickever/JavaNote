# 01_数据采集层

## 1. 数仓分层介绍

**为什么要分层**

为了当出现多个需求时候，多需求可以同复用一张表，而不是从头到尾再抽取一遍，从而实现数据的**复用性**，另外还有解耦、拓展性高等好处

![page2_image3](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82page2_image3.jpg)

而**普通的实时计算**优先考虑时效性，所以从数据源采集经过实时计算直接得到结果。如此做时效性更好，但是弊端是由于计算过程中的中间结果没有沉淀下来，所以当面对大量实时需求的时候，计算的复用性较差，开发成本随着需求增加直线上升。

![page1_image2](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82page1_image2.jpg)



**分层介绍**

ODS：原始数据，日志和业务数据

DWD：根据数据对象为单位进行分流（例如侧输出流），比如订单、页面访问等等

DIM：维度数据（放HBase，因为实时流中Join相当于查询，且维度数据需要永久保存）

DWM：对于部分数据对象进行进一步加工，比如独立访问、跳出行为，也可以和维度进行关联，形成宽表，依旧是明细数据。

DWS：根据某个主题将多个事实数据轻度聚合，形成主题宽表。（存到Clickhouse）

ADS：把ClickHouse中的数据根据可视化需进行筛选聚合（不落盘）





## 2.  实时需求概览

**离线计算与实时计算的比较**

**离线计算**：就是在计算开始前已知所有输入数据，输入数据不会产生变化，一般计算量级较大，计算时间也较长。例如今天早上一点，把昨天累积的日志，计算出所需结果。最经典的就是 Hadoop 的 MapReduce 方式；

一般是根据前一日的数据生成报表，虽然统计指标、报表繁多，但是对时效性不敏感。从技术操作的角度，这部分属于批处理的操作。即根据确定范围的数据一次性计算。

**实时计算**：输入数据是可以以序列化的方式一个个输入并进行处理的，也就是说在开始的时候并不需要知道所有的输入数据。与离线计算相比，运行时间短，计算量级相对较小。强调计算过程的时间要短，即所查当下给出结果。

主要侧重于对当日数据的实时监控，通常业务逻辑相对离线需求简单一下，统计指标也少一些，但是更注重数据的时效性，以及用户的交互性。从技术操作的角度，这部分属于流处理的操作。根据数据源源不断地到达进行实时的运算。

**即席查询**：需求临时性（Presto、Kylin）



**实时需求种类**

- **日常统计报表或分析图中需要包含当日部分**
- **实时数据大屏监控**
- **数据预警或提示**
- **实时推荐系统**



## 3. 架构分析

**离线**

![image-20220201143631865](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82image-20220201143631865.png)

**实时**

![image-20220201143711363](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82image-20220201143711363.png)



**Sqoop**：

- 全量：where 1=1
- 增量：创建时间  = 当天
- 增量及变化：创建时间  = 当天  or  操作时间  = 当天
- 特殊：只导入一次



### 3.1 FlumeSource

**FlumeTailSource**：

- 优点：断点续传，多目录多文件实时监控
- 缺点：文件更名后，会重新读取造成数据重复
- 原因：flume监控文件的inode、filename、偏移量，inode和filename一旦改变就认为是一个新文件
- 零点漂移：如果flume在0点前挂掉，且在0点后才重启，0点后日志更名，导致挂掉后到0点前那一部分数据丢失
- 解决办法：
  - 使用不更名日志框架（logback），但上游可能不愿意改
  - 自己改flume源码，让TailSource只监控inode
- 可不可以把监控文件名写死呢
  - 不可以，当若上游使用log4j，零点时日志文件更名并生成新的同名文件，inode值会变，偏移量会变
  - 如果flume在11点半挂了，0点启动，由于文件更名，导致中间30分钟数据监控不到



### 3.2 KafkaChannel

**KafkaChannel**：

- 优点：数据写入Kafka省去一层sink



Kafak的一些面试点：

**Producer**

- ACK（0，1，-1）
- 拦截器、序列化、分区器
- 发送流程、sender、main
- 幂等性、事务
- 分区规则
  - 有指定分区规则就发往指定分区（优先级最高）
  - 没有指定分区就根据Key来Hash
  - 没有指定分区也没有指定Key，轮询（粘性）



**Broker**

- Topic
  - 副本：高可靠，ISR（LEO、HW）
  - 分区：高并发，负载均衡，防止热点



**Consumer**

- 分区分配规则
- offset保存问题
  - 默认__consumer_offsets  Topic
  - 手动维护（MySQL），保存offset&保存数据写到一个事务，实现精准一次消费



优化、监控、配置、数据量、峰值速度



### 3.3 架构对比

**离线架构**

- 优点：耦合性低，稳定性高
- 缺点：时效性差
- 说明：
  - 追求系统稳定性
  - 耦合性低，稳定性高
  - 考虑未来发展，数据量一定很高



**实时架构**

- 优点：时效性好
- 缺点：耦合性高，稳定性低
- 说明：
  - Flink时效性好
  - Kafka集群高可用，挂两台没关系
  - 数据量小，在同机房传输没问题
  - 架构师定的



## 4. 日志采集

![page7_image2](https://raw.githubusercontent.com/flickever/NotePictures/master/%E9%A1%B9%E7%9B%AE/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/01_%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E5%B1%82page7_image2.jpg)

由于条件限制，只能直接对Spring boot做请求发送假数据，不再经过Nginx

**日志采集**

Spring Boot：数据接口

- Controller：拦截用户请求，调用Service，响应请求
- Service：调用DAO，加工数据
- DAO(Mapper)：获取数据
- 持久化层：存储数据



**Springboot注解**

**@Controller**：用于标记在一个类上，使用它标记的类就是一个SpringMVC的 Controller类

**@ResponseBody**：把return的结果变成JSON对象返回。（如果没有这个注解，这个方法只能返回要跳转的路径即跳转的html/JSP页面。有这个注解，可以不跳转页面，只返回JSON数据）

**@RequestMapping**：给出外界访问方法的路径，或者说触发路径 ，触发条件

**@RestController**：相当于 @Controller ＋ @ResponseBody 合在一起的作用

**@RequestParam**：用于将指定的请求参数赋值给方法中的形参，可以赋默认值



启动消费者：

```shell
bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic ods_base_log
```



## 5. Nginx

负责反向代理，代理服务端

启动命令

```
sudo /opt/module/nginx/sbin/nginx
```

停止命令

```
sudo /opt/module/nginx/sbin/nginx -s stop
```



**集群打印log启动脚本**

```shell
#!/bin/bash
JAVA_BIN=/opt/module/jdk1.8.0_212/bin/java
APPNAME=gmall-logger.jar
case $1 in
"start")
 {
 for i in hadoop102 hadoop103 hadoop104
 do
 echo "========: $i==============="
 ssh $i "$JAVA_BIN -Xms32m -Xmx64m -jar 
/opt/module/gmall-flink/rt_applog/$APPNAME >/dev/null 2>&1 &"
 done
 };;
 "stop")
 { 
 for i in hadoop102 hadoop103 hadoop104
 do
 echo "========: $i==============="
 ssh $i "ps -ef|grep $APPNAME | grep -v grep|awk '{print \$2}'| xargs kill" >/dev/null 2>&1
 done
 };;
 esac
```



## 6. 采集工具

**Flink CDC**

DataStream方式

- 优点：多库多表
- 缺点：需要自定义反序列化器

FlinkSQL

- 优点：不需要自定义反序列化器，只需要一个JavaBean即可
- 缺点：只能单表



**Flink CDC、MaxWell、Canal对比**

**数据更新**：

- 更新数据时，Flink CDC显示所有old字段数据，MaxWell和Canal只会显示被修改的字段数据
- 一次插入多条数据时：Flink CDC和MaxWell会分层多条消息；Canal会把多条消息打包成一个数组，只用一条数据发过来，后续想用还要自己做炸裂操作

**数据初始化**：

- Flink CDC：有，可以多库多表
- MaxWell：有，只能单表
- Canal：无

**断点续传**：

- Flink CDC：CheckPoint
- MaxWell：MySQL
- Canal：本地磁盘

**封装格式**：

- Flink CDC：可以自定义
- MaxWell：JSON
- Canal：JSON（c/s模式也可以自定义）

**高可用**：

- Flink CDC：有
- MaxWell：无
- Canal：有（需要zk）